# üéì Data Engineering & AI Mastery: 2026 Career Pivot
**Student:** Nabiya Maredia  
**Goal:** Senior-Level Data Engineer (AI Infrastructure focus)  
**Timeline:** 4.5 Months + 1.5 Months Interview Prep  

---

## üìÖ The 4.5-Month Intensive Curriculum

| Module | Sub-Topics & Deep Dives | Learning Outcomes | Portfolio Lab | Time Allocated |
| :--- | :--- | :--- | :--- | :--- |
| **M00: AI-Native Foundations** | ‚Ä¢ Modern Git/GitHub Flow<br>‚Ä¢ Linux CLI & Bash Scripting<br>‚Ä¢ Cursor AI & Prompt Engineering for Devs<br>‚Ä¢ Setting up an AI-Augmented Workflow | Master the "AI Pair Programmer" workflow to code 3x faster than 2008 standards. | **Lab 0:** Automated GitHub Actions for repo health. | **1 Week** |
| **M01: Python for Data Logic** | ‚Ä¢ Collections (Lists, Dicts, Sets, Tuples)<br>‚Ä¢ List & Dict Comprehensions<br>‚Ä¢ Functional Programming (Lambda/Map)<br>‚Ä¢ Error Handling & Logging<br>‚Ä¢ API Consumption (Requests library) | Build resilient scripts that can ingest and validate messy JSON data from real-world APIs. | **Lab 1:** "The Data Scraper" - Resilient script pulling & cleaning live API data. | **2 Weeks** |
| **M02: Data Transformation** | ‚Ä¢ Pandas: DataFrames & Series<br>‚Ä¢ Vectorized Operations (Performance)<br>‚Ä¢ Polars: High-speed Data Manipulation<br>‚Ä¢ Data Profiling & Quality Auditing | Transition from "row-by-row" logic to "vectorized" bulk data processing. | **Lab 2:** "The Explorer" - Notebook analyzing a 100k+ row dataset. | **2 Weeks** |
| **M03: SQL & Modern Warehousing** | ‚Ä¢ Window Functions (Rank, Lead/Lag, Over)<br>‚Ä¢ CTEs (Common Table Expressions)<br>‚Ä¢ Star Schema & Snowflake Schema Design<br>‚Ä¢ Snowflake/BigQuery Performance Tuning | Level up from 3/10 to 8/10. Write production-grade, cost-optimized analytical queries. | **Lab 3:** "The Architect" - Star-schema model for an E-commerce DB. | **3 Weeks** |
| **M04: Workflow Orchestration** | ‚Ä¢ Apache Airflow Core Concepts<br>‚Ä¢ Designing DAGs (Directed Acyclic Graphs)<br>‚Ä¢ Task Dependencies & Retries<br>‚Ä¢ Airflow Variables & Connections | Automate and schedule manual tasks into self-healing, professional data pipelines. | **Lab 4:** "The Conductor" - Airflow DAG running a daily ETL process. | **2 Weeks** |
| **M05: Cloud & Big Data (Spark)** | ‚Ä¢ AWS Fundamentals (S3, IAM, Lambda, Glue)<br>‚Ä¢ PySpark: Distributed Computing Basics<br>‚Ä¢ Modern Lakehouse Formats (Apache Iceberg)<br>‚Ä¢ Big Data Performance & Shuffling | Learn to process data volumes that "broke" 2008-era single-node systems. | **Lab 5:** "The Cloud Processor" - Spark job processing 1M+ rows on AWS. | **3 Weeks** |
| **M06: Real-Time Streaming** | ‚Ä¢ Apache Kafka: Producers & Consumers<br>‚Ä¢ Event-Driven Architectures<br>‚Ä¢ Stream Transformation (KSQL/Spark Streaming)<br>‚Ä¢ Handling Late-Arriving Data | Move and process data in milliseconds. This is the #1 "Leverage" skill of 2026. | **Lab 6:** "The Live Streamer" - Kafka producer/consumer for real-time logs. | **2 Weeks** |
| **M07: MLOps & AI Infrastructure** | ‚Ä¢ Docker: Containerizing Workloads<br>‚Ä¢ Terraform: Infrastructure as Code (IaC)<br>‚Ä¢ Vector Databases (Pinecone/Weaviate)<br>‚Ä¢ RAG (Retrieval Augmented Generation) Pipelines | Bridge the gap between engineering and production AI/ML systems. | **Lab 7:** "The AI Engine" - Deploy a RAG-based AI agent using your data. | **2 Weeks** |
| **M08: Capstone Project** | ‚Ä¢ System Design & Architecture<br>‚Ä¢ Cost Estimation & FinOps<br>‚Ä¢ End-to-End Pipeline Integration<br>‚Ä¢ Documentation & Presentation | Prove you can architect, build, and maintain a full-scale cloud data platform. | **The Grand Finale:** Full Cloud-Native Pipeline from API to AI Bot. | **2 Weeks** |
| **M09: Career Launchpad** | ‚Ä¢ Resume/LinkedIn Re-branding<br>‚Ä¢ SQL & Python Live Coding Prep<br>‚Ä¢ Behavioral Interviews (Explaining the Gap)<br>‚Ä¢ Salary Negotiation (2026 Market Rates) | Market yourself as a mature, AI-Proof Senior Engineer and land the offer. | **Career Launch:** Finalized Portfolio & Interview Blitz. | **Continuous** |

---

## üõ†Ô∏è Personal Tech Stack (2026)
* **Languages:** Python 3.12+, SQL (PostgreSQL/Snowflake flavor)
* **Tools:** Cursor AI, Git/GitHub, Docker, Terraform
* **Cloud:** AWS (Glue, S3, Lambda, Athena)
* **Engines:** Spark (PySpark), Kafka, Airflow, dbt
* **AI Integration:** Pinecone, OpenAI API, LangChain